{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbe5e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import pyspark.sql.utils\n",
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30c64e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#criando sessão Spark\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c98979",
   "metadata": {},
   "outputs": [],
   "source": [
    "#criando um dataframe a partir de uma leitura de um csv em pandas\n",
    "data = pd.read_csv(\"https://olinda.bcb.gov.br/olinda/servico/PTAX/versao/v1/odata/CotacaoDolarPeriodo(dataInicial=@dataInicial,dataFinalCotacao=@dataFinalCotacao)?@dataInicial=%2701-01-2019%27&@dataFinalCotacao=%2712-31-2025%27&$top=9000&$format=text/csv&$select=cotacaoCompra,cotacaoVenda,dataHoraCotacao\")\n",
    "df = spark.createDataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e5004f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.display() #visualiza o dataframe\n",
    "df.printSchema() #verifica ostipos de dados do df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facd2447",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lendo diferentes tipos de arquivos\n",
    "dfs = spark.read.format(\"csv\").option(\"sep\",\";\").option(\"inferschema\", True).option(\"header\",True).load(\"path do arquivo\")\n",
    "dfp = spark.read.format(\"parquet\").option(\"header\",True).load(\"path do arquivo\")\n",
    "dfj = spark.read.format(\"json\").option(\"header\",True).load(\"path do arquivo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd0c384",
   "metadata": {},
   "outputs": [],
   "source": [
    "#com withColumn podemos fazer várias tratativas de dados conforme abaixo:(renomear colunas, alterar tipo de dados, replace etc...)\n",
    "df = dfs.withColumnRenamed(\"Item Type\",\"Item_Type\"\n",
    "                     ).withColumnRenamed(\"Sales Channel\",\"Sales_Channel\"\n",
    "                     ).withColumnRenamed(\"Order Priority\", \"Order_Priority\"\n",
    "                     ).withColumnRenamed(\"Order Date\",\"Order_Date\"\n",
    "                     ).withColumn(\"Order_Date\",to_date(\"Order_Date\",\"dd/MM/yyyy\")\n",
    "                     ).withColumnRenamed(\"Order ID\", \"Order_ID\"\n",
    "                     ).withColumn(\"Order_ID\",col(\"Order_ID\").cast(IntegerType())\n",
    "                     ).withColumnRenamed(\"Ship Date\",\"Ship_Date\"\n",
    "                     ).withColumn(\"Ship_Date\",to_date(\"Ship_Date\",\"dd/MM/yyyy\")\n",
    "                     ).withColumnRenamed(\"Units Sold\", \"Units_Sold\"\n",
    "                     ).withColumn(\"Units_Sold\",col(\"Units_Sold\").cast(IntegerType())\n",
    "                     ).withColumnRenamed(\"Unit Price\", \"Unit_Price\"\n",
    "                     ).withColumn(\"Unit_Price\",regexp_replace(\"Unit_Price\",\",\",\".\").cast(\"float\")\n",
    "                     ).withColumnRenamed(\"Unit Cost\",\"Unit_Cost\"\n",
    "                     ).withColumn(\"Unit_Cost\",regexp_replace(\"Unit_Cost\",\",\",\".\").cast(\"float\")\n",
    "                     ).withColumnRenamed(\"Total Revenue\", \"Total_Revenue\"\n",
    "                     ).withColumn(\"Total_Revenue\",regexp_replace(\"Total_Revenue\",\",\",\".\").cast(\"float\")\n",
    "                     ).withColumnRenamed(\"Total Cost\",\"Total_Cost\"\n",
    "                     ).withColumn(\"Total_Cost\",regexp_replace(\"Total_Cost\",\",\",\".\").cast(\"float\")\n",
    "                     ).withColumnRenamed(\"Total Profit\", \"Total_Profit\"\n",
    "                     ).withColumn(\"Total_Profit\",regexp_replace(\"Total_Profit\",\",\",\".\").cast(\"float\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696f524f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unir dois df's em um com o comando \"union\"\n",
    "df1\n",
    "df2\n",
    "df3 = d1.union(df2)\n",
    "#logo o df3 estará com os dados do df1 e df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c1f07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#contando as linhas de um df\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3165cd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lendo arquivos do dbfs databricks\n",
    "df1 = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"dbfs:/FileStore/shared_uploads/adones.inocencio@blueshift.com.br/marca_carro.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3076f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#criando uma view sql\n",
    "df_carros.createOrReplaceTempView(\"carros\")\n",
    "\n",
    "#criando um dataframe a partir de uma query sql\n",
    "df_carros_sql = spark.sql(\"\"\"select id_carro as id, modelo_carro as modelo from carros\"\"\")\n",
    "display(df_carros_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8040fe8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select com Spark\n",
    "from pyspark.sql.functions import col\n",
    "#df_carros_spark = df_carros.selectExpr(\"modelo_carro as modelo\" , \"id_carro as id\") #nomeando as colunas com \"as\" e Expr depois do select\n",
    "#nomeando com alias\n",
    "df_carros_spark = df_carros.select(col(\"modelo_carro\").alias(\"modelo\"), col(\"id_carro\").alias(\"id\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e42bb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtro com SQL\n",
    "df_carros.createOrReplaceTempView(\"carros\") #criando uma view sql\n",
    "\n",
    "#dataframe com o resultado da consulta sql\n",
    "df_carros_sql = spark.sql(\"\"\"\n",
    "select * from carros\n",
    "where modelo_carro = \"Avalon\"\n",
    "and id_carro = 1\n",
    "or modelo_carro = \"Golf\"\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd86110",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtros usando pyspark\n",
    "\n",
    "\"\"\"\n",
    "#usando apenas where (pode usar o comando \"filter\" no lugar do where) \n",
    "display(\n",
    "    df_carros.where(\"id_carro = 1\")\n",
    ")\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "#usando com o comando \"col\"\n",
    "display(\n",
    "    df_carros.where(\n",
    "        col(\"id_carro\") == \"1\")\n",
    ")\n",
    "\"\"\"\n",
    "#usando & ou | (or)\n",
    "display(\n",
    "    df_carros.where(\n",
    "        (col(\"id_carro\") == \"1\") &\n",
    "        (col(\"modelo_carro\") == \"Avalon\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5eec39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#criando um dataframe a partir da consulta\n",
    "\n",
    "df_carro_pyspark = df_carros.where(df_carros[\"id_carro\"] == \"1\")\n",
    "display(df_carro_pyspark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c42d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#valores distintos sql\n",
    "%sql\n",
    "select distinct * from carros3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94659248",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace sql\n",
    "%sql\n",
    "select replace(preco, '$', '#') as preco from carros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcb49da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#No pyspark para eliminar os duplicados pode usar tanto o distinct como o dropDuplicate, faz o mesmo trabalho\n",
    "df_carrospyspark_3 = df_carros_3.distinct()\n",
    "print(df_carrospyspark_3.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c06d0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para substituir valores no pyspark usamos a função regexp_replace, passamos a coluna, o caractere a ser alterado (colocar a contrabarra \\ antes do caractere, e depois o que você quer que seja colocado no lugar, nesse caso colocamos um espaço vazio, mas poderia ser R$)\n",
    "from pyspark.sql.functions import regexp_replace\n",
    "\n",
    "df_carrospyspark_4= df_carros_3\n",
    "df_carrospyspark_4 = df_carrospyspark_4.withColumn(\"preco\", regexp_replace(\"preco\", \"\\$\", \"\"))\n",
    "display(df_carrospyspark_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421e8680",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fazendo tipagem de dados com withColumn e cast\n",
    "df_carros_spark = df_carros_3\n",
    "df_carros_spark = df_carros_spark.withColumn(\"id_carro\", col(\"id_carro\").cast(\"int\")).withColumn(\"preco\", col(\"preco\").cast(\"double\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49903dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#alterando o tipo de dado no pyspark com select...Você pode usar as funções de tipo também, IntergerType, DoubleType etc... porém tem que rodar o \"from pyspark.sql.types import *\"\n",
    "\n",
    "from pyspark.sql.functions import *\n",
    "df_carros_spark = df_carros_3 \n",
    "df_carros_spark = df_carros_spark.select(\n",
    "    col(\"id_carro\").cast(\"int\"),\n",
    "    col(\"preco\").cast(\"double\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed5ba86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_carros_6 = spark.read.format(\"csv\").option(\"header\", True).load(\"/mnt/adones-inocencio/modelo_carro.csv\")\n",
    "\n",
    "#substituindo o $ por um espaço vazio na coluna preço\n",
    "df_carros_6 = df_carros_6.withColumn(\n",
    "    \"preco\", regexp_replace(col(\"preco\"), \"\\$\", \"\"))\n",
    "\n",
    "#alterando os tipos de dados das colunas\n",
    "df_carros_6 = df_carros_6.select(\n",
    "    col(\"id_carro\").cast(IntegerType()),\n",
    "    \"modelo_carro\", \n",
    "    col(\"preco\").cast(DoubleType()),\n",
    "    col(\"cod_marca\").cast(IntegerType())\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7269b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#criando uma tempview\n",
    "df.createOrReplaceTempView(\"nova_view\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be34b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#No SQL usando o Like tudo que você coloca entre aspas e porcentagem ele puxa, ex: Se for uma lista de nomes e tiver \n",
    "#varios \"Paulo\" e você filtrar como \"%ulo%\" ele vai filtrar tudo que tem nesse intervalo. Se tirar o % do final ele vai puxar\n",
    "#tudo que termina no intervalo que colocou, no caso tudo que acaba com \"ulo\", se você mtira a % do final e deixa só no inicio,\n",
    "#ele filtra tudo que começa com o intervalo solicitado: \"%aul%\" -> Filtra o que tem dentro do intervalo \"%pa\" -> Filtra o que \n",
    "#começa com o intervalo \"lo%\" -> Filtra o que acaba com o intervalo\n",
    "\n",
    "%sql\n",
    "select *\n",
    "from carros6\n",
    "where modelo_carro like \"Es%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f79193d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#usando between\n",
    "%sql\n",
    "select * \n",
    "from carros6\n",
    "where preco between 50000 and 75000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6839b3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Usando o like no spark\n",
    "\n",
    "df_carros6_spark = df_carros_6\n",
    "\n",
    "df_carros6_spark = df_carros6_spark.where(\n",
    "    col(\"modelo_carro\").like(\"%alo%\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9354b6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Usando o between no spark\n",
    "\n",
    "df_carros7_spark = df_carros_6\n",
    "\n",
    "df_carros7_spark = df_carros7_spark.where(\n",
    "    col(\"preco\").between(50000, 65000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe9c50c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "52634da84371cba311ea128a5ea7cdc41ff074b781779e754b270ff9f8153cee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
